{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c29bdef",
   "metadata": {},
   "source": [
    "# V1: Target-Encoded Categorical Ensemble\n",
    "\n",
    "Early iteration combining competition data with original diabetes dataset, using target encoding for categorical features and 10-fold validation. This version experiments with domain-specific feature engineering and categorical handling.\n",
    "\n",
    "**Key Features:**\n",
    "- Combined 700K competition + 100K original reference data\n",
    "- 800K total samples for training\n",
    "- Target encoding for categorical variables\n",
    "- Label encoding for tree models\n",
    "- 10-Fold Stratified Cross-Validation\n",
    "- XGBoost, LightGBM, CatBoost ensemble\n",
    "- 5000 estimators per model\n",
    "- Weighted averaging (45/35/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c357a",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f4f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f53e0",
   "metadata": {},
   "source": [
    "## 2. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competition data\n",
    "train_comp = pd.read_csv(\"/kaggle/input/playground-series-s5e12/train.csv\")\n",
    "test_comp  = pd.read_csv(\"/kaggle/input/playground-series-s5e12/test.csv\")\n",
    "submission = pd.read_csv(\"/kaggle/input/playground-series-s5e12/sample_submission.csv\")\n",
    "\n",
    "original = pd.read_csv(\"/kaggle/input/diabetes-health-indicators-dataset/diabetes_dataset.csv\")\n",
    "\n",
    "print(f\"Competition train shape : {train_comp.shape}\")\n",
    "print(f\"Original real data shape : {original.shape}\")\n",
    "print(f\"Test shape              : {test_comp.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3f9005",
   "metadata": {},
   "source": [
    "## 3. Combine Competition + Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2bee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only shared columns\n",
    "common_cols = [col for col in train_comp.columns if col in original.columns and col != \"id\"]\n",
    "\n",
    "train = train_comp[common_cols + [\"diagnosed_diabetes\"]].copy()\n",
    "orig  = original[common_cols + [\"diagnosed_diabetes\"]].copy()\n",
    "\n",
    "train = pd.concat([train, orig], ignore_index=True)\n",
    "print(f\"\\nCombined training data shape → {train.shape} (competition + original)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc44fdbf",
   "metadata": {},
   "source": [
    "## 4. Categorical Encoding\n",
    "\n",
    "Apply target encoding (smoothed) for categorical features to capture target distribution patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233b495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\"gender\", \"ethnicity\", \"education_level\", \"income_level\",\n",
    "                \"employment_status\", \"smoking_status\"]\n",
    "\n",
    "# Target encoding (smoothed with regularization)\n",
    "global_mean = train[\"diagnosed_diabetes\"].mean()\n",
    "\n",
    "for col in cat_features:\n",
    "    target_mean = train.groupby(col)[\"diagnosed_diabetes\"].mean()\n",
    "    count = train.groupby(col)[\"diagnosed_diabetes\"].count()\n",
    "    smooth = (target_mean * count + global_mean * 20) / (count + 20)\n",
    "    \n",
    "    train[col + \"_te\"] = train[col].map(smooth)\n",
    "    test_comp[col + \"_te\"] = test_comp[col].map(smooth).fillna(global_mean)\n",
    "\n",
    "# Label encoding for tree models\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col].astype(str))\n",
    "    test_comp[col] = le.transform(test_comp[col].astype(str))\n",
    "\n",
    "print(\"Categorical encoding complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0f9bab",
   "metadata": {},
   "source": [
    "## 5. Prepare Final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a481364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop([\"id\", \"diagnosed_diabetes\"], axis=1, errors=\"ignore\")\n",
    "y = train[\"diagnosed_diabetes\"]\n",
    "X_test = test_comp.drop(\"id\", axis=1, errors=\"ignore\")\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Total features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a901e7",
   "metadata": {},
   "source": [
    "## 6. 10-Fold Ensemble Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50011d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "oof_preds = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(X_test))\n",
    "\n",
    "print(\"\\nStarting 10-Fold Training...\\n\")\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"  → Fold {fold+1}/10\", end=\" \")\n",
    "    \n",
    "    X_trn, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
    "    y_trn, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # XGBoost\n",
    "    model1 = xgb.XGBClassifier(\n",
    "        n_estimators=5000,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.02,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.7,\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    )\n",
    "    model1.fit(X_trn, y_trn, eval_set=[(X_val, y_val)], \n",
    "               early_stopping_rounds=150, verbose=False)\n",
    "    \n",
    "    # LightGBM\n",
    "    model2 = lgb.LGBMClassifier(\n",
    "        n_estimators=5000,\n",
    "        max_depth=9,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=256,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.7,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    model2.fit(X_trn, y_trn, eval_set=[(X_val, y_val)],\n",
    "               callbacks=[lgb.early_stopping(150)], verbose=False)\n",
    "    \n",
    "    # CatBoost\n",
    "    model3 = cb.CatBoostClassifier(\n",
    "        iterations=5000,\n",
    "        depth=9,\n",
    "        learning_rate=0.03,\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "        early_stopping_rounds=150\n",
    "    )\n",
    "    model3.fit(X_trn, y_trn, eval_set=(X_val, y_val), verbose=False)\n",
    "    \n",
    "    # Blend per fold\n",
    "    val_blend = (model1.predict_proba(X_val)[:,1] * 0.45 +\n",
    "                 model2.predict_proba(X_val)[:,1] * 0.35 +\n",
    "                 model3.predict_proba(X_val)[:,1] * 0.20)\n",
    "    \n",
    "    test_blend = (model1.predict_proba(X_test)[:,1] * 0.45 +\n",
    "                  model2.predict_proba(X_test)[:,1] * 0.35 +\n",
    "                  model3.predict_proba(X_test)[:,1] * 0.20) / skf.n_splits\n",
    "    \n",
    "    oof_preds[val_idx] = val_blend\n",
    "    test_preds += test_blend\n",
    "    \n",
    "    fold_auc = roc_auc_score(y_val, val_blend)\n",
    "    print(f\"| AUC = {fold_auc:.6f}\")\n",
    "\n",
    "print(f\"\\nFinal CV AUC: {roc_auc_score(y, oof_preds):.6f}\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49971df",
   "metadata": {},
   "source": [
    "## 7. Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d1bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"diagnosed_diabetes\"] = test_preds\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"\\nsubmission.csv saved!\")\n",
    "print(f\"Mean predicted probability: {test_preds.mean():.5f}\")\n",
    "print(f\"Min predicted probability: {test_preds.min():.5f}\")\n",
    "print(f\"Max predicted probability: {test_preds.max():.5f}\")\n",
    "\n",
    "print(\"\\nFirst few predictions:\")\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1436c85",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**V1: Target-Encoded Categorical Ensemble**\n",
    "\n",
    "**Architecture:**\n",
    "- **Data Combination**: 700K competition + 100K original = 800K training samples\n",
    "- **Categorical Encoding**:\n",
    "  - Target encoding (smoothed): captures category relationship with target\n",
    "  - Label encoding: enables tree model categorical support\n",
    "  - Regularization: smoothing factor=20 prevents overfit\n",
    "- **Features**: All shared columns between datasets\n",
    "- **Target Encoding Variables**: gender, ethnicity, education_level, income_level, employment_status, smoking_status\n",
    "- **Model Configuration**:\n",
    "  - 10-Fold Stratified CV\n",
    "  - 5000 estimators per model\n",
    "  - Learning rate: 0.02-0.03 (conservative)\n",
    "  - Early stopping: 150 rounds\n",
    "- **Ensemble**: XGB (45%) + LGBM (35%) + CB (20%)\n",
    "\n",
    "V1 explores data combination strategies and categorical feature encoding, using a large training set (800K samples) to improve model robustness."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
